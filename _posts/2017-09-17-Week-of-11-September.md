---
layout: post
title: "Week of 11 September 2017"
---

- Completed the Udacity course on Deep Learning ([Link](https://www.udacity.com/course/deep-learning--ud730)).
  - The parts of the course completed this week covered deep learning for text, namely Word2Vec (Skip-Gram & CBOW) & LSTM.
  - All completed assignments can be found [here](https://github.com/SuyashLakhotia/DeepLearningAssignments).
  - Also used [this blog post](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) and its [second part](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/) to understand Word2Vec better.
- Read the TensorFlow tutorials for [MNIST (Basic Neural Network)](https://www.tensorflow.org/get_started/mnist/beginners), [MNIST (Convolutional Neural Network)](https://www.tensorflow.org/get_started/mnist/pros) & [Word2Vec](https://www.tensorflow.org/tutorials/word2vec), all of which I've already implemented as part of the Udacity assignments.
